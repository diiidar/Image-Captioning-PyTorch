{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 1328792,
          "sourceType": "datasetVersion",
          "datasetId": 771078
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "image_captioning",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diiidar/Image-Captioning-PyTorch/blob/main/image_captioning_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "aladdinpersson_flickr8kimagescaptions_path = kagglehub.dataset_download('aladdinpersson/flickr8kimagescaptions')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "MzmGBHiOAELl"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /kaggle/working/checkpoints"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:09.138235Z",
          "iopub.execute_input": "2025-03-13T03:14:09.13859Z",
          "iopub.status.idle": "2025-03-13T03:14:09.256355Z",
          "shell.execute_reply.started": "2025-03-13T03:14:09.138563Z",
          "shell.execute_reply": "2025-03-13T03:14:09.255285Z"
        },
        "id": "9KpQQVT9AELn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import string\n",
        "import re\n",
        "import torchvision\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:09.257779Z",
          "iopub.execute_input": "2025-03-13T03:14:09.258142Z",
          "iopub.status.idle": "2025-03-13T03:14:17.298738Z",
          "shell.execute_reply.started": "2025-03-13T03:14:09.258103Z",
          "shell.execute_reply": "2025-03-13T03:14:17.297972Z"
        },
        "id": "UDctPmS1AELn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:17.300472Z",
          "iopub.execute_input": "2025-03-13T03:14:17.300825Z",
          "iopub.status.idle": "2025-03-13T03:14:17.304356Z",
          "shell.execute_reply.started": "2025-03-13T03:14:17.300803Z",
          "shell.execute_reply": "2025-03-13T03:14:17.303581Z"
        },
        "id": "ly0qVC2HAELn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext cudf.pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:17.305589Z",
          "iopub.execute_input": "2025-03-13T03:14:17.305867Z",
          "iopub.status.idle": "2025-03-13T03:14:25.430747Z",
          "shell.execute_reply.started": "2025-03-13T03:14:17.305829Z",
          "shell.execute_reply": "2025-03-13T03:14:25.429855Z"
        },
        "id": "3uTuFsJ3AELn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:25.431728Z",
          "iopub.execute_input": "2025-03-13T03:14:25.432135Z",
          "iopub.status.idle": "2025-03-13T03:14:25.441809Z",
          "shell.execute_reply.started": "2025-03-13T03:14:25.432112Z",
          "shell.execute_reply": "2025-03-13T03:14:25.44102Z"
        },
        "id": "c3cmINt1AELo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_IMAGES_DIR = \"/kaggle/input/flickr8kimagescaptions/flickr8k/images\"\n",
        "LABEL_PATH = \"/kaggle/input/flickr8kimagescaptions/flickr8k/captions.txt\"\n",
        "\n",
        "UNK = \"#UNK\"\n",
        "PAD = \"#PAD\"\n",
        "START = \"#START\"\n",
        "END = \"#END\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:25.442758Z",
          "iopub.execute_input": "2025-03-13T03:14:25.443183Z",
          "iopub.status.idle": "2025-03-13T03:14:25.471911Z",
          "shell.execute_reply.started": "2025-03-13T03:14:25.443132Z",
          "shell.execute_reply": "2025-03-13T03:14:25.471104Z"
        },
        "id": "bK0zW17bAELo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(LABEL_PATH)\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:25.47267Z",
          "iopub.execute_input": "2025-03-13T03:14:25.472965Z",
          "iopub.status.idle": "2025-03-13T03:14:25.8896Z",
          "shell.execute_reply.started": "2025-03-13T03:14:25.472937Z",
          "shell.execute_reply": "2025-03-13T03:14:25.888808Z"
        },
        "id": "-1o3ZTwCAELo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "def clean_text(row):\n",
        "    row = str(row).strip()\n",
        "    row = row.lower()\n",
        "    return regex.sub(\"\", row)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:25.891818Z",
          "iopub.execute_input": "2025-03-13T03:14:25.892067Z",
          "iopub.status.idle": "2025-03-13T03:14:25.895968Z",
          "shell.execute_reply.started": "2025-03-13T03:14:25.892046Z",
          "shell.execute_reply": "2025-03-13T03:14:25.895291Z"
        },
        "id": "0uANQV22AELo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [col.strip() for col in df.columns]\n",
        "df[\"caption\"] = df[\"caption\"].apply(clean_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:25.897407Z",
          "iopub.execute_input": "2025-03-13T03:14:25.897635Z",
          "iopub.status.idle": "2025-03-13T03:14:26.500602Z",
          "shell.execute_reply.started": "2025-03-13T03:14:25.897614Z",
          "shell.execute_reply": "2025-03-13T03:14:26.499962Z"
        },
        "id": "49gTwXULAELo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"length\"] = df[\"caption\"].apply(lambda row: len(row.strip().split()))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:26.501441Z",
          "iopub.execute_input": "2025-03-13T03:14:26.501742Z",
          "iopub.status.idle": "2025-03-13T03:14:26.649244Z",
          "shell.execute_reply.started": "2025-03-13T03:14:26.501712Z",
          "shell.execute_reply": "2025-03-13T03:14:26.648413Z"
        },
        "id": "KTxBKFi1AELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(df['length'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:26.650041Z",
          "iopub.execute_input": "2025-03-13T03:14:26.650391Z",
          "iopub.status.idle": "2025-03-13T03:14:27.018142Z",
          "shell.execute_reply.started": "2025-03-13T03:14:26.650366Z",
          "shell.execute_reply": "2025-03-13T03:14:27.017231Z"
        },
        "id": "T2jmLr9gAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "captions = df[\"caption\"].tolist()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.019Z",
          "iopub.execute_input": "2025-03-13T03:14:27.019291Z",
          "iopub.status.idle": "2025-03-13T03:14:27.051045Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.019253Z",
          "shell.execute_reply": "2025-03-13T03:14:27.050438Z"
        },
        "id": "KOfXWqGNAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq = {}\n",
        "for caption in captions:\n",
        "    caption = caption.strip()\n",
        "    for word in caption.split():\n",
        "        if word not in word_freq:\n",
        "            word_freq[word] = 0\n",
        "        word_freq[word] += 1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.051702Z",
          "iopub.execute_input": "2025-03-13T03:14:27.051943Z",
          "iopub.status.idle": "2025-03-13T03:14:27.177755Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.051914Z",
          "shell.execute_reply": "2025-03-13T03:14:27.177021Z"
        },
        "id": "iqRRGqRiAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dict(sorted(word_freq.items(), key=lambda item: item[1], reverse=True)[:10])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.17863Z",
          "iopub.execute_input": "2025-03-13T03:14:27.178947Z",
          "iopub.status.idle": "2025-03-13T03:14:27.188818Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.178916Z",
          "shell.execute_reply": "2025-03-13T03:14:27.188138Z"
        },
        "id": "Dr8ZXFkkAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(captions, word_freq, count_threshold=5):\n",
        "    vocab = {\n",
        "        PAD: 0,\n",
        "        UNK: 1,\n",
        "        START: 2,\n",
        "        END: 3\n",
        "    }\n",
        "    index = 4\n",
        "\n",
        "    for caption in captions:\n",
        "        caption = caption.strip().split(\" \")\n",
        "        for word in caption:\n",
        "            if word and word_freq[word] >= count_threshold and word not in vocab:\n",
        "                vocab[word] = index\n",
        "                index += 1\n",
        "\n",
        "    inv_vocab = {v: k for k, v in vocab.items()}\n",
        "    return vocab, inv_vocab"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.189679Z",
          "iopub.execute_input": "2025-03-13T03:14:27.189861Z",
          "iopub.status.idle": "2025-03-13T03:14:27.205506Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.189843Z",
          "shell.execute_reply": "2025-03-13T03:14:27.204925Z"
        },
        "id": "geOCaNXeAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vocab, inv_vocab = build_vocab(captions, word_freq)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.20622Z",
          "iopub.execute_input": "2025-03-13T03:14:27.206458Z",
          "iopub.status.idle": "2025-03-13T03:14:27.298785Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.206438Z",
          "shell.execute_reply": "2025-03-13T03:14:27.298012Z"
        },
        "id": "MEPvnsHwAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_captions(captions, vocab, max_length=30):\n",
        "    tokens = [[vocab[PAD]]*max_length for _ in range(len(captions))]\n",
        "    for i, caption in enumerate(captions):\n",
        "        caption = caption.strip().split()\n",
        "        tokens[i][0] = vocab[START]\n",
        "        j = 1\n",
        "        for word in caption[:max_length-2]:\n",
        "            if word not in vocab:\n",
        "                tokens[i][j] = vocab[UNK]\n",
        "            else:\n",
        "                tokens[i][j] = vocab[word]\n",
        "            j += 1\n",
        "        tokens[i][j] = vocab[END]\n",
        "    return tokens"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.299616Z",
          "iopub.execute_input": "2025-03-13T03:14:27.299906Z",
          "iopub.status.idle": "2025-03-13T03:14:27.304832Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.299861Z",
          "shell.execute_reply": "2025-03-13T03:14:27.304082Z"
        },
        "id": "qJiez2QvAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = convert_captions(captions, vocab)\n",
        "img_paths = list(df[\"image\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.305819Z",
          "iopub.execute_input": "2025-03-13T03:14:27.306093Z",
          "iopub.status.idle": "2025-03-13T03:14:27.684681Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.306073Z",
          "shell.execute_reply": "2025-03-13T03:14:27.683787Z"
        },
        "id": "v0MWgzkEAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCaptioningDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, img_paths, tokens):\n",
        "        self.img_paths = [os.path.join(INPUT_IMAGES_DIR, p) for p in img_paths][:-20000]\n",
        "        self.tokens = tokens[:-20000]\n",
        "        assert len(self.img_paths) == len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_paths[index]\n",
        "        token = self.tokens[index]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = self._resize_img(img, shape=(300, 300))\n",
        "        img = torchvision.transforms.ToTensor()(img)\n",
        "        token = torch.as_tensor(token)\n",
        "        return img, token\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def _resize_img(self, img, shape=(300, 300)):\n",
        "        h, w = img.shape[0], img.shape[1]\n",
        "        pad_left = 0\n",
        "        pad_right = 0\n",
        "        pad_top = 0\n",
        "        pad_bottom = 0\n",
        "        if h > w:\n",
        "            diff = h - w\n",
        "            pad_top = diff - diff // 2\n",
        "            pad_bottom = diff // 2\n",
        "        else:\n",
        "            diff = w - h\n",
        "            pad_left = diff - diff // 2\n",
        "            pad_right = diff // 2\n",
        "        cropped_img = img[pad_top:h-pad_bottom, pad_left:w-pad_right, :]\n",
        "        cropped_img = cv2.resize(cropped_img, shape)\n",
        "        return cropped_img"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.685584Z",
          "iopub.execute_input": "2025-03-13T03:14:27.685869Z",
          "iopub.status.idle": "2025-03-13T03:14:27.692785Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.685835Z",
          "shell.execute_reply": "2025-03-13T03:14:27.692176Z"
        },
        "id": "Ibap6vPSAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImageCaptioningDataset(img_paths, tokens)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.693492Z",
          "iopub.execute_input": "2025-03-13T03:14:27.693741Z",
          "iopub.status.idle": "2025-03-13T03:14:27.751417Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.693708Z",
          "shell.execute_reply": "2025-03-13T03:14:27.750779Z"
        },
        "id": "yz-MjDk2AELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 26\n",
        "NUM_VOCAB = len(vocab)\n",
        "BATCH_SIZE = 21\n",
        "EPOCH = 5"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.752043Z",
          "iopub.execute_input": "2025-03-13T03:14:27.752241Z",
          "iopub.status.idle": "2025-03-13T03:14:27.755782Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.752223Z",
          "shell.execute_reply": "2025-03-13T03:14:27.754904Z"
        },
        "id": "5YkbDRkfAELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, is_last=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.is_last = is_last\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        preact = out\n",
        "        out = F.relu(out)\n",
        "        if self.is_last:\n",
        "            return out, preact\n",
        "        else:\n",
        "            return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.756576Z",
          "iopub.execute_input": "2025-03-13T03:14:27.756809Z",
          "iopub.status.idle": "2025-03-13T03:14:27.772781Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.75679Z",
          "shell.execute_reply": "2025-03-13T03:14:27.771947Z"
        },
        "id": "hqHHCZO5AELp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, is_last=False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.is_last = is_last\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        preact = out\n",
        "        out = F.relu(out)\n",
        "        if self.is_last:\n",
        "            return out, preact\n",
        "        else:\n",
        "            return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.776798Z",
          "iopub.execute_input": "2025-03-13T03:14:27.77704Z",
          "iopub.status.idle": "2025-03-13T03:14:27.793533Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.777021Z",
          "shell.execute_reply": "2025-03-13T03:14:27.792955Z"
        },
        "id": "64_bz-C8AELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, in_channel=3, zero_init_residual=False):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for i in range(num_blocks):\n",
        "            stride = strides[i]\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, layer=100):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.794559Z",
          "iopub.execute_input": "2025-03-13T03:14:27.794747Z",
          "iopub.status.idle": "2025-03-13T03:14:27.809208Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.79473Z",
          "shell.execute_reply": "2025-03-13T03:14:27.808388Z"
        },
        "id": "Sde8UCkAAELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(**kwargs):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "\n",
        "def resnet34(**kwargs):\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet50(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet101(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.809925Z",
          "iopub.execute_input": "2025-03-13T03:14:27.810153Z",
          "iopub.status.idle": "2025-03-13T03:14:27.828354Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.810135Z",
          "shell.execute_reply": "2025-03-13T03:14:27.827733Z"
        },
        "id": "ULKyoes2AELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {\n",
        "    'resnet18': [resnet18, 512],\n",
        "    'resnet34': [resnet34, 512],\n",
        "    'resnet50': [resnet50, 2048],\n",
        "    'resnet101': [resnet101, 2048],\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.829021Z",
          "iopub.execute_input": "2025-03-13T03:14:27.829242Z",
          "iopub.status.idle": "2025-03-13T03:14:27.849444Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.829224Z",
          "shell.execute_reply": "2025-03-13T03:14:27.84887Z"
        },
        "id": "ON8RqsgqAELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetEncoder(nn.Module):\n",
        "    \"\"\"ResNet-based encoder for image captioning.\"\"\"\n",
        "    def __init__(self, name='resnet34'):\n",
        "        super(ResNetEncoder, self).__init__()\n",
        "        model_fun, dim_in = model_dict[name]\n",
        "        self.encoder = model_fun()\n",
        "\n",
        "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-2])\n",
        "\n",
        "        # Adaptive pooling to get fixed feature size\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.feature_dim = dim_in\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)  # Extract feature maps\n",
        "        features = self.avgpool(features)  # Pool to fixed size\n",
        "        features = torch.flatten(features, 1)  # Flatten to (batch_size, feature_dim)\n",
        "\n",
        "        return features\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.850095Z",
          "iopub.execute_input": "2025-03-13T03:14:27.850329Z",
          "iopub.status.idle": "2025-03-13T03:14:27.866631Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.85031Z",
          "shell.execute_reply": "2025-03-13T03:14:27.865861Z"
        },
        "id": "fiYOnbsaAELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, num_vocab) -> None:\n",
        "        super().__init__()\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.num_vocab = num_vocab\n",
        "        self.embedding = nn.Embedding(num_embeddings=num_vocab, embedding_dim=256, padding_idx=0)\n",
        "        self.num_layers = 1\n",
        "        self.bidirectional = False\n",
        "        self.rnn = nn.LSTM(input_size=256, hidden_size=256, num_layers=self.num_layers, batch_first=True, bidirectional=self.bidirectional)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, num_vocab)\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, input, img_embeded, prediction=False):\n",
        "        img_embeded = self.bottleneck(img_embeded)\n",
        "        img_embeded = torch.stack([img_embeded]*(self.num_layers), dim=0)\n",
        "        if prediction:\n",
        "            output = []\n",
        "            hidden = (img_embeded, img_embeded)\n",
        "            out = input\n",
        "            # print('decoder forward check 3')\n",
        "            while out != vocab[END] and len(output) <= MAX_LENGTH:\n",
        "                out = torch.tensor([[out]]).to(\"cuda\")\n",
        "                out = self.embedding(out)\n",
        "                out, hidden = self.rnn(out, hidden)\n",
        "                out = self.classifier(out)\n",
        "                out = self.softmax(out)\n",
        "                out = torch.argmax(out, dim=-1)\n",
        "                out = out.squeeze().item()\n",
        "                output.append(out)\n",
        "        else:\n",
        "            input = self.embedding(input)\n",
        "            output, (h, c) = self.rnn(input, (img_embeded, img_embeded))\n",
        "            output = self.classifier(output)\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.867445Z",
          "iopub.execute_input": "2025-03-13T03:14:27.867696Z",
          "iopub.status.idle": "2025-03-13T03:14:27.883688Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.867676Z",
          "shell.execute_reply": "2025-03-13T03:14:27.882927Z"
        },
        "id": "KfcbJijVAELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCaptioningModel:\n",
        "\n",
        "    def __init__(self, encoder : ResNetEncoder, decoder : RNNDecoder, train_dataset : ImageCaptioningDataset):\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.encoder = encoder.to(self.device)\n",
        "        self.encoder.eval()\n",
        "        self.decoder = decoder.to(self.device)\n",
        "        self.train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        self.optimizer = optim.Adam(decoder.parameters())\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def predict(self, img):\n",
        "        print(\"Predict method called!\")\n",
        "        with torch.no_grad():\n",
        "            if img.dim() == 3:\n",
        "                img = img.unsqueeze(0)\n",
        "            img = img.to(self.device)\n",
        "\n",
        "            img_embed = self.encoder(img)\n",
        "            print(\"Image embedding shape:\", img_embed.shape)\n",
        "\n",
        "            caption = [vocab[START]]\n",
        "            hidden = (self.decoder.bottleneck(img_embed), self.decoder.bottleneck(img_embed))\n",
        "\n",
        "            for _ in range(MAX_LENGTH):\n",
        "                inp = torch.tensor([[caption[-1]]]).to(self.device)\n",
        "                inp = self.decoder.embedding(inp)\n",
        "                out, hidden = self.decoder.rnn(inp, hidden)\n",
        "                out = self.decoder.classifier(out)\n",
        "\n",
        "                print(\"Raw output logits shape:\", out.shape)\n",
        "\n",
        "                out = F.softmax(out, dim=-1)\n",
        "                print(\"Softmax output shape:\", out.shape)\n",
        "                print(\"Softmax probabilities:\", out.squeeze().cpu().numpy())\n",
        "\n",
        "                out = torch.argmax(out, dim=-1).item()\n",
        "                print(\"Chosen token index:\", out)\n",
        "\n",
        "                if out == vocab[END]:\n",
        "                    break\n",
        "                caption.append(out)\n",
        "\n",
        "            text = [inv_vocab[t] for t in caption]\n",
        "            return \" \".join(text)\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        for e in range(EPOCH):\n",
        "            pbar = tqdm(self.train_dataloader, desc=\"Epoch: {}\".format(e+1))\n",
        "            for i, (img, caption) in enumerate(pbar):\n",
        "                img = img.to(self.device)\n",
        "                caption = caption.to(self.device)\n",
        "                img_embed = self.encoder(img)\n",
        "                output = self.decoder(caption[:, :-1], img_embed)\n",
        "                output = output.permute(0, 2, 1)\n",
        "                loss = self.loss(output, caption[:, 1:])\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                pbar.set_description(desc=\"Epoch \" + str(e+1) + \" - Loss: %.5f\" % (loss.item()))\n",
        "                if (i + 1) % 5 == 0:\n",
        "                    torch.save(self.decoder.state_dict(), \"/kaggle/working/checkpoints/decoder_checkpoint.pth\")\n",
        "                    torch.save(self.encoder.state_dict(), \"/kaggle/working/checkpoints/encoder_checkpoint.pth\")\n",
        "                if ((i+1)%100) == 0:\n",
        "                    plt.imshow(img[-1].cpu().detach().numpy().transpose((1, 2, 0)))\n",
        "                    output = self.predict(img[-1].unsqueeze(0))\n",
        "                    plt.title(output)\n",
        "                    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T08:14:51.532504Z",
          "iopub.execute_input": "2025-03-13T08:14:51.532815Z",
          "iopub.status.idle": "2025-03-13T08:14:51.544733Z",
          "shell.execute_reply.started": "2025-03-13T08:14:51.532792Z",
          "shell.execute_reply": "2025-03-13T08:14:51.543952Z"
        },
        "id": "5yysahRdAELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = ResNetEncoder()\n",
        "rnn = RNNDecoder(num_vocab=NUM_VOCAB)\n",
        "model = ImageCaptioningModel(encoder=cnn, decoder=rnn, train_dataset=dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:27.906124Z",
          "iopub.execute_input": "2025-03-13T03:14:27.906305Z",
          "iopub.status.idle": "2025-03-13T03:14:28.613619Z",
          "shell.execute_reply.started": "2025-03-13T03:14:27.906289Z",
          "shell.execute_reply": "2025-03-13T03:14:28.612988Z"
        },
        "id": "x4JtjvHgAELq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "model.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T03:14:28.614283Z",
          "iopub.execute_input": "2025-03-13T03:14:28.614485Z",
          "iopub.status.idle": "2025-03-13T07:33:54.485515Z",
          "shell.execute_reply.started": "2025-03-13T03:14:28.614467Z",
          "shell.execute_reply": "2025-03-13T07:33:54.484728Z"
        },
        "scrolled": true,
        "id": "LCwmbZRVAELr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import torch\n",
        "\n",
        "class ImageCaptioningEvaluator:\n",
        "    def __init__(self, model, dataset, vocab, inv_vocab):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.vocab = vocab\n",
        "        self.inv_vocab = inv_vocab\n",
        "\n",
        "    def evaluate(self, num_samples=100):\n",
        "        bleu_scores = []\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            img, true_caption = self.dataset[i]\n",
        "            img = img.unsqueeze(0).to(self.model.device)\n",
        "            generated_caption = self.model.predict(img)\n",
        "\n",
        "            true_caption_words = [self.inv_vocab[t] for t in true_caption.tolist() if t not in {self.vocab[START], self.vocab[END]}]\n",
        "            generated_caption_words = generated_caption.split()\n",
        "\n",
        "            bleu = sentence_bleu([true_caption_words], generated_caption_words)\n",
        "            bleu_scores.append(bleu)\n",
        "        avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "        print(f\"BLEU Score: {avg_bleu:.4f}\")\n",
        "\n",
        "        return avg_bleu"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T09:43:50.562085Z",
          "iopub.execute_input": "2025-03-13T09:43:50.562389Z",
          "iopub.status.idle": "2025-03-13T09:43:50.568469Z",
          "shell.execute_reply.started": "2025-03-13T09:43:50.562366Z",
          "shell.execute_reply": "2025-03-13T09:43:50.567456Z"
        },
        "id": "rt3O41BxAELr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = ImageCaptioningEvaluator(model, dataset, vocab, inv_vocab)\n",
        "bleu_score = evaluator.evaluate(num_samples=500)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T09:43:51.950061Z",
          "iopub.execute_input": "2025-03-13T09:43:51.950357Z",
          "iopub.status.idle": "2025-03-13T09:44:17.29657Z",
          "shell.execute_reply.started": "2025-03-13T09:43:51.950333Z",
          "shell.execute_reply": "2025-03-13T09:44:17.295823Z"
        },
        "id": "K_h02pfHAELr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def show_prediction(index):\n",
        "    img = mpimg.imread('/kaggle/input/flickr8kimagescaptions/flickr8k/images/'+img_paths[index])\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    res = model.predict(dataset.__getitem__(index)[0].unsqueeze(0).to(device))\n",
        "    print(res)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T08:05:46.165409Z",
          "iopub.execute_input": "2025-03-13T08:05:46.165707Z",
          "iopub.status.idle": "2025-03-13T08:05:46.169946Z",
          "shell.execute_reply.started": "2025-03-13T08:05:46.165684Z",
          "shell.execute_reply": "2025-03-13T08:05:46.169155Z"
        },
        "id": "3SOxR309AELr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "show_prediction(4)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T08:12:56.608538Z",
          "iopub.execute_input": "2025-03-13T08:12:56.608824Z",
          "iopub.status.idle": "2025-03-13T08:12:56.800295Z",
          "shell.execute_reply.started": "2025-03-13T08:12:56.6088Z",
          "shell.execute_reply": "2025-03-13T08:12:56.799603Z"
        },
        "id": "GNe0cGx-AELr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "show_prediction(10)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-13T08:49:36.849505Z",
          "iopub.execute_input": "2025-03-13T08:49:36.849845Z",
          "iopub.status.idle": "2025-03-13T08:49:37.082772Z",
          "shell.execute_reply.started": "2025-03-13T08:49:36.849816Z",
          "shell.execute_reply": "2025-03-13T08:49:37.082122Z"
        },
        "id": "PjQVe-ExAELr"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}